{
  "hash": "89163430cd21a21f1cd7e7a0aba33dd1",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Detecting Anomalies in Credit Card Transactions\"\nsubtitle: \"Proposal\"\nauthor: \n  - name: \"Reilly Rodriguez Spencer\"\n    affiliations:\n      - name: \"College of Information Science, University of Arizona\"\ndescription: \"Exploring unsupervised anomaly detection methods on imbalanced financial data\"\nformat:\n  html:\n    code-tools: true\n    code-overflow: wrap\n    code-line-numbers: true\n    embed-resources: true\neditor: visual\ncode-annotations: hover\nexecute:\n  warning: false\njupyter: python3\n---\n\n\n\n## Dataset\n\n\n\nThis project uses the Credit Card Fraud Detection dataset, containing transactions made by European cardholders over two days in 2013. The dataset includes 284,807 transactions, with only 492 labeled as fraudulent (Class = 1), making it highly imbalanced. Features are anonymized and PCA-transformed for confidentiality, with the exception of Time, Amount, and Class.\n\nAlthough the dataset includes labeled anomalies, I am approaching this as an unsupervised anomaly detection task, simulating a real-world scenario where fraudulent examples are not labeled during model training. Labels are withheld during training and used only for model evaluation.\n\n## Questions\n\n1.  How well do unsupervised ensemble-based models detect fraudulent transactions when labels are withheld during training?\n2.  How do distance-based and statistical approaches to outlier detection—such as k-NN and z-score methods—compare to ensemble-based methods in identifying rare but meaningful anomalies?\n\n## Analysis plan\n\n-   Data Preprocessing (August 6–7)\n\n    -   Load and clean the dataset; scale relevant features.\n\n-   Modeling: Unsupervised Learning (August 8–10)\n\n    -   Implement anomaly detection methods.\n\n-   Evaluation (August 11–13)\n\n    -   Assess model performance using the fraud labels for metrics like ROC AUC and precision-recall.\n\n-   Visualization (August 13–16)\n\n    -   Create performance plots and visual summaries of detected anomalies.\n\n-   Presentation Prep (August 17–19)\n\n    -   Finalize presentation materials and write-up of results.\n\n",
    "supporting": [
      "proposal_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}